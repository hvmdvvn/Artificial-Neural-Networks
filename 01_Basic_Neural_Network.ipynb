{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPbcFovkPHM/VIv/iuzWPPa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hvmdvvn/Artificial-Neural-Networks/blob/main/01_Basic_Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hc7V4xZSGZ2O"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "  return 1 / ( 1 + np.exp(-1) )\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "  return x * (1 - x)"
      ],
      "metadata": {
        "id": "CCjg8VbIGmjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer_size = 2\n",
        "hidden_layer_size = 2\n",
        "output_layer_size = 1"
      ],
      "metadata": {
        "id": "FoDcpb3FJ7pv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "weights_input_hidden = np.random.uniform(size=(input_layer_size, hidden_layer_size))\n",
        "weights_hidden_output = np.random.uniform(size=(hidden_layer_size, output_layer_size))"
      ],
      "metadata": {
        "id": "i_VRtY6rKLSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Hidden Input Layers's Weights\", weights_input_hidden.shape)\n",
        "print(\"Ouput Layers's Weights\", weights_hidden_output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptxU_WE-M10t",
        "outputId": "0d5536a5-ab29-4b3d-eab0-794c8f9564b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hidden Input Layers's Weights (2, 2)\n",
            "Ouput Layers's Weights (2, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bias_hidden = np.random.uniform(size=(1, hidden_layer_size))\n",
        "bias_output = np.random.uniform(size=(1, output_layer_size))"
      ],
      "metadata": {
        "id": "nBkEIoOsMvLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Hidden Input Layers's Bias\", bias_hidden.shape)\n",
        "print(\"Output Layer's Bias\", bias_output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IICt1VpRM-bG",
        "outputId": "cf06b975-6118-4d17-fc91-03bdbbce2304"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hidden Input Layers's Bias (1, 2)\n",
            "Output Layer's Bias (1, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVJehh6XM_pl",
        "outputId": "a54858e6-6e34-4d88-81f9-5e5480338e67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.array([[0],[1],[1],[0]])\n",
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYxC2KerO_ja",
        "outputId": "e0c8f032-d11a-4904-d9be-73e52b55fac5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.1\n",
        "epochs = 10000"
      ],
      "metadata": {
        "id": "mqZkX7sOPI0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    # ---- Forward pass ----\n",
        "    hidden_input = np.dot(X, weights_input_hidden) + bias_hidden\n",
        "    hidden_output = sigmoid(hidden_input)\n",
        "\n",
        "    final_input = np.dot(hidden_output, weights_hidden_output) + bias_output\n",
        "    final_output = sigmoid(final_input)\n",
        "\n",
        "    # ---- Loss (Mean Squared Error) ----\n",
        "    loss = y - final_output\n",
        "    mse = np.mean(np.square(loss))\n",
        "\n",
        "    # ---- Backpropagation ----\n",
        "    d_output = loss * sigmoid_derivative(final_output)\n",
        "    error_hidden = d_output.dot(weights_hidden_output.T)\n",
        "    d_hidden = error_hidden * sigmoid_derivative(hidden_output)\n",
        "\n",
        "    # ---- Update weights & biases (Gradient Descent) ----\n",
        "    weights_hidden_output -= hidden_output.T.dot(d_output) * learning_rate\n",
        "    weights_input_hidden -= X.T.dot(d_hidden) * learning_rate\n",
        "    bias_hidden -= np.sum(d_hidden, axis=0, keepdims=True) * learning_rate\n",
        "    bias_output -= np.sum(d_output, axis=0, keepdims=True) * learning_rate\n",
        "\n",
        "    # ---- Print progress ----\n",
        "\n",
        "print(\"Final Output:\")\n",
        "print(final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "DbiThD1dPR2n",
        "outputId": "7190ff61-3c5a-481a-95c3-4355938f6825"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'numpy.float64' object has no attribute 'dot'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3508152567.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# ---- Update weights & biases (Gradient Descent) ----\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mweights_hidden_output\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mhidden_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_output\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mweights_input_hidden\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_hidden\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mbias_hidden\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.float64' object has no attribute 'dot'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# -----------------------------\n",
        "# Activation functions\n",
        "# -----------------------------\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "# -----------------------------\n",
        "# Example dataset (XOR problem)\n",
        "# -----------------------------\n",
        "X = np.array([\n",
        "    [0, 0],\n",
        "    [0, 1],\n",
        "    [1, 0],\n",
        "    [1, 1]\n",
        "])   # shape (4,2)\n",
        "\n",
        "y = np.array([\n",
        "    [0],\n",
        "    [1],\n",
        "    [1],\n",
        "    [0]\n",
        "])   # shape (4,1)\n",
        "\n",
        "# -----------------------------\n",
        "# Hyperparameters\n",
        "# -----------------------------\n",
        "input_size = X.shape[1]   # 2 features\n",
        "hidden_size = 4           # hidden neurons\n",
        "output_size = y.shape[1]  # 1 output\n",
        "learning_rate = 0.1\n",
        "epochs = 10000\n",
        "\n",
        "# -----------------------------\n",
        "# Weights & biases initialization\n",
        "# -----------------------------\n",
        "np.random.seed(42)  # reproducibility\n",
        "\n",
        "weights_input_hidden = np.random.randn(input_size, hidden_size) * 0.01\n",
        "weights_hidden_output = np.random.randn(hidden_size, output_size) * 0.01\n",
        "\n",
        "bias_hidden = np.zeros((1, hidden_size))\n",
        "bias_output = np.zeros((1, output_size))\n",
        "\n",
        "# -----------------------------\n",
        "# Training loop\n",
        "# -----------------------------\n",
        "for epoch in range(epochs):\n",
        "    # ---- Forward pass ----\n",
        "    hidden_input = np.dot(X, weights_input_hidden) + bias_hidden\n",
        "    hidden_output = sigmoid(hidden_input)\n",
        "\n",
        "    final_input = np.dot(hidden_output, weights_hidden_output) + bias_output\n",
        "    final_output = sigmoid(final_input)\n",
        "\n",
        "    # ---- Loss (Mean Squared Error) ----\n",
        "    loss = y - final_output\n",
        "    mse = np.mean(np.square(loss))\n",
        "\n",
        "    # ---- Backpropagation ----\n",
        "    d_output = loss * sigmoid_derivative(final_output)\n",
        "    error_hidden = d_output.dot(weights_hidden_output.T)\n",
        "    d_hidden = error_hidden * sigmoid_derivative(hidden_output)\n",
        "\n",
        "    # ---- Update weights & biases (Gradient Descent) ----\n",
        "    weights_hidden_output -= hidden_output.T.dot(d_output) * learning_rate\n",
        "    weights_input_hidden -= X.T.dot(d_hidden) * learning_rate\n",
        "    bias_hidden -= np.sum(d_hidden, axis=0, keepdims=True) * learning_rate\n",
        "    bias_output -= np.sum(d_output, axis=0, keepdims=True) * learning_rate\n",
        "\n",
        "    # ---- Print progress ----\n",
        "    if epoch % 1000 == 0:\n",
        "        print(f\"Epoch: {epoch}, MSE: {mse:.6f}\")\n",
        "\n",
        "# -----------------------------\n",
        "# Final Output\n",
        "# -----------------------------\n",
        "print(\"\\nFinal Output after Training:\")\n",
        "print(final_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NF7c--3PQfx3",
        "outputId": "10eb0e2d-b131-41c0-a6cb-e8e82b992de6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, MSE: 0.250001\n",
            "Epoch: 1000, MSE: 0.498036\n",
            "Epoch: 2000, MSE: 0.499164\n",
            "Epoch: 3000, MSE: 0.499479\n",
            "Epoch: 4000, MSE: 0.499624\n",
            "Epoch: 5000, MSE: 0.499708\n",
            "Epoch: 6000, MSE: 0.499761\n",
            "Epoch: 7000, MSE: 0.499799\n",
            "Epoch: 8000, MSE: 0.499826\n",
            "Epoch: 9000, MSE: 0.499847\n",
            "\n",
            "Final Output after Training:\n",
            "[[2.36362271e-04]\n",
            " [1.36473338e-04]\n",
            " [1.36256658e-04]\n",
            " [8.52648764e-05]]\n"
          ]
        }
      ]
    }
  ]
}